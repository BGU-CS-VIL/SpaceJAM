{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to your main working directory\n",
    "# %cd [your-cwd]\n",
    "# %pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trainer and evaluate PCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from spacejam.trainer import trainer_from_checkpoint, Trainer\n",
    "from utilities.run_utils import forward_inference_all\n",
    "\n",
    "model_pt_path = 'your_pt_path.pt'\n",
    "trainer : Trainer = trainer_from_checkpoint(model_pt_path)\n",
    "transformers_list, encoded_features_list, inputs_dicts_list = forward_inference_all(trainer.dataset, trainer.autoencoder, trainer.stn, trainer.atlas_handler, trainer.loss_handler, train_with_reflections=trainer.train_with_reflections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dict = trainer.eval()\n",
    "for k, v in eval_dict.items():\n",
    "    print(f'{k}: {v.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate warped images and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_TO_SHOW = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access the homography transformation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacejam.models.transformers.homography_transformer import HomographyTransformer\n",
    "\n",
    "for i in range(NUM_IMAGES_TO_SHOW):\n",
    "    transformer: HomographyTransformer = transformers_list[i].transformers[0]  # type: ignore\n",
    "    print(transformer.theta.cpu().numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some images warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "images = []\n",
    "for i in range(NUM_IMAGES_TO_SHOW):\n",
    "    image = inputs_dicts_list[i]['images']\n",
    "    transformed_image = transformers_list[i](image)\n",
    "    vis = torch.cat([image[0], transformed_image[0]], dim=1)  \n",
    "    images.append(vis)\n",
    "\n",
    "grid = make_grid(images, nrow=NUM_IMAGES_TO_SHOW, padding=0)  \n",
    "plt.figure(figsize=(5*NUM_IMAGES_TO_SHOW, 5))  \n",
    "plt.imshow(grid.permute(1, 2, 0).cpu().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the atlas after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_warped = torch.stack([tr(inputs_dicts['images'])[0] for tr, inputs_dicts in zip(transformers_list, inputs_dicts_list)])\n",
    "encoded_features = torch.stack([tr(encoded_features)[0] for tr, encoded_features in zip(transformers_list, encoded_features_list)])\n",
    "masks_warped = torch.stack([tr(inputs_dicts['masks'])[0] for tr, inputs_dicts in zip(transformers_list, inputs_dicts_list)])\n",
    "\n",
    "encoded_features = (encoded_features - encoded_features.min()) / (encoded_features.max() - encoded_features.min())\n",
    "\n",
    "vis = encoded_features.mean(dim=0) * masks_warped.median(dim=0).values\n",
    "plt.imshow(vis.permute(1,2,0).cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spacejam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
